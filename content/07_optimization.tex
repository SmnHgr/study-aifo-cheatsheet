\section{Optimization}
\begin{itemize}
    \item Training or learning in AI often suggests an algorithm performing some sort of optimization
    \item It is the problem of finding a set of inputs to an objective function that results in a maximum or minimum function evaluation
    \item In our examples the objective is to minimize the loss function
\end{itemize}

\subsection{Gradient Descent}
At any location [a,b] we look at the error-gradient in the neighbourhood of [a,b] and move a (small) step in the direction where the error shrinks the most.
By repeating this procedure, we will eventually arrive at the location where the error is smallest.

\begin{itemize}
    \item Iterative Method/Procedure
    \item Each iteration, the model parameters are updated such as that the Loss (MSE) is reduced
    \item Move along a trajectory which includes fewer points
    \item At each point of the trajectory we evaluate the gradient of the error function
    \item At each iteration, we would have to iterate over all $N = 1'000$ points to calculate the gradient of the loss function.
\end{itemize}

\textbf{MSE formula}
\begin{center}
    $E = \frac{1}{2N} * \large\displaystyle\sum_{i = 1}^{N}(\hat{y_i} - (a*x_i + b))^2$
\end{center}

\textbf{Gradient of E}

Calculate these two partial derivatives

\begin{center}
    $\frac{\partial E}{\partial a} = \frac{1}{N}\sum_{i=1}^N (y_i - (a \cdot x_i + b)) \cdot -x_i$
\end{center}

\begin{center}
    $\frac{\partial E}{\partial b} = \frac{1}{N}\sum_{i=1}^N (y_i - (a \cdot x_i + b)) \cdot -1$
\end{center}

\begin{center}
    $
     \textrm{Gradient of E} = \begin{bmatrix}
                                  \frac{\partial E}{\partial a} \\
                                  \frac{\partial E}{\partial b} \\
     \end{bmatrix}
     =\begin{bmatrix}
          \frac{1}{N}\sum_{i=1}^N (y_i - (a \cdot x_i + b))(-x_i) \\
          \frac{1}{N}\sum_{i=1}^N (y_i - (a \cdot x_i + b))(-1) \\
     \end{bmatrix}
    $
\end{center}

\textbf{Update Rule}

\begin{center}
    $
    \begin{bmatrix}
        a \\
        b \\
    \end{bmatrix}_{t+1}
    =    \begin{bmatrix}
             a \\
             b \\
    \end{bmatrix}_{t} - \alpha
    \begin{bmatrix}
        \frac{\partial E}{\partial a} \\
        \frac{\partial E}{\partial b} \\
    \end{bmatrix} \Big\rvert _{\begin{bmatrix}
                                   a \\
                                   b \\
    \end{bmatrix}_{t} }
    $
\end{center}

The algorithm starts at some initial position $[a, b]_{t0}$. \\
Then, the update rule is applied repeatedly.
The number of update steps needed to come ``close enough'' to the minimum depends on the problem.

\subsection{Stochastic Gradient Descent (SGD)}
we do not need the exact gradient to find a trajectory toward the minimum. Instead, at each iteration we can randomly pick a few datapoints and use them to calculate an approximation of the gradient.
\begin{itemize}
    \item At each iteration, the gradient is calculated on a (randomly selected) subset of the data
    \item For a fixed learning rate, SGD does not converge
\end{itemize}

\textbf{Mini-batches} \\

\begin{itemize}
    \item $1<n<N$
    \item Increasing the batch-size will reduce the variance of the gradient estimation
    \item batch-size $n=1$ yields a very noisy gradient
    \item batch-size $n=N$ is expensive to calculate
    \item often mini-batches of size $n=32$ or $n=64$ are used
\end{itemize}

\textbf{Annealed SGD}
\begin{itemize}
    \item The learning rate alpha is reduced over time
    \item This is called (simulated) annealing
    \item There are different options (called schedules) how to reduce alpha over time
    \item A fixed learning rate $\alpha$ does not converge. The algorithm keeps fluctuating around the minimum. Annealed SGD solves this appearent contradiction by adapting the learning rate. It starts with a large $\alpha$ and reduces it over time
\end{itemize}

\subsubsection{General remarks on SGD}
\begin{itemize}
    \item Gradient-based methods only work if we can express a Loss function as a differentiable function
    \item SGD is dealing with only a single datum at each iteration. This is very inefficient and rarely used.
    \item Batch- or mini-batch gradient-descent is usually used
\end{itemize}
